&&& FILE: ./.gitignore
&&& CONTENT:
# Ignore local data files
data_local/

# Python cache
__pycache__/
*.pyc

# Environment variables
.env

# Other ignores
*.so

# tileset
backend/tileset/*
!backend/tileset/README.md

*.gml
*.gfs
*.obj

#venv
venv/
.venv/
.conda

node_modules/

postgres_data/

&&& FILE: ./docker-compose.yml
&&& CONTENT:
services:
  postgis:
    container_name: easyopen_db
    image: postgis/postgis:17-3.5
    restart: always
    ports:
      - 8735:5432
    environment:
      POSTGRES_PASSWORD: barcelona
    volumes:
      - ./postgres_data:/var/lib/postgresql/data
      - ./backend/db/init.sql:/docker-entrypoint-initdb.d/init.sql
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "postgres"]
      interval: 10s
      timeout: 5s
      retries: 20

  easyopen_backend:
    container_name: easyopen_backend
    build:
      context: ./backend
      dockerfile: Dockerfile
    command: uvicorn app.main:app --host 0.0.0.0 --port 5400 --reload
    volumes:
      - ./backend:/app
      - ./backend/tileset:/app/tileset
      - ./backend/tempfiles:/app/tempfiles
    ports:
      - 5400:5400
    environment:
      DATABASE_URL: postgresql+asyncpg://postgres:barcelona@postgis:5432/easyopendata_database
    depends_on:
      postgis:
        condition: service_healthy

  easyopen_frontend:
    container_name: easyopen_frontend
    build:
      context: ./frontend
      dockerfile: Dockerfile
    volumes:
      - ./frontend:/app
      - /app/node_modules
    ports:
      - 5173:5173
    environment:
      VITE_BACKEND_URL: https://easyopen-server.i-am-hellguz.uk

volumes:
  postgres_data:


&&& FILE: ./README.md
&&& CONTENT:
# EasyOpenData

## Open Data Extractor for German Spatial Datasets

### Overview

EasyOpenData is a platform that provides an easy-to-use interface for accessing and downloading spatial data from German open data sources, covering all Bundesl√§nder. It standardizes the diverse formats in which these datasets are available and presents them to users via an intuitive web interface.

Users can interact with a map, select areas of interest (via polygons), and choose the data layers they wish to download. Available data types include:

- **3D Buildings (LOD1/LOD2)**

The platform processes the selected data and provides it in the user's desired format after payment, either as a direct download or via email.

---

### Key Features

- **Map-Based User Interface**: Allows users to interact with spatial data visually by selecting areas on a map.
- **Multi-Format Support**: Data is standardized into a unified format, enabling seamless querying and export.
- **Dynamic Data Processing**: Fetches and processes data only for the area selected by the user, ensuring efficiency.
- **Real-Time Visualization**: Users can preview data layers on the map as they select their areas of interest.
- **Payment Integration**: Secure payment processing via Stripe.
- **Scalable Backend**: Built for performance, capable of handling large datasets from multiple regions.

---

### Technologies Used

#### Backend

- **PostGIS**: Spatial database for storing and querying geographic data efficiently.
- **Python FastAPI**: Backend framework for building APIs to handle user requests and interact with PostGIS.
- **GDAL**: Used for data conversion between formats.
- **Docker**: Containerized deployment for portability and scalability.
- **Stripe API**: For handling payment transactions.

#### Frontend

- **React**: JavaScript library for building user interfaces.
- **MapLibre GL JS**: Interactive map interface for visualization and area selection.
- **Deck.gl**: For rendering 3D data on the map.
- **Mapbox Draw**: Allows users to draw shapes on the map.

---

### Getting Started

#### Prerequisites

- **Docker** and **Docker Compose** installed on your system.
- **Node.js** and **npm/yarn** (for frontend development).
- **Python 3.10+** (for backend development).

#### Setup Instructions

##### Clone the Repository

```bash
git clone https://github.com/your-repo/easyopendata.git
cd easyopendata
```

##### Environment Variables

Create a `.env` file in both the `backend` and `frontend` directories if needed to set environment variables.

##### Run with Docker Compose

```bash
docker-compose up --build
```

This command will:

- Start the PostGIS database.
- Build and run the backend FastAPI server.
- Build and run the frontend React application.

##### Access the Application

- **Frontend**: [http://localhost:5173](http://localhost:5173)
- **Backend API**: [http://localhost:5400](http://localhost:5400)

---

### Usage

1. **Open the Web Application**: Navigate to [http://localhost:5173](http://localhost:5173) in your browser.
2. **Select an Area**: Use the drawing tools to select an area on the map.
3. **Choose Data Layers**: Select the data layers you wish to download.
4. **Payment**: Proceed to payment if required.
5. **Download Data**: After processing, download your data in the desired format.

---

### Project Structure

- **backend/**: Contains the FastAPI backend application.
  - `app/`: FastAPI application code.
  - `db/`: Database initialization scripts.
  - `ingestion/`: Scripts for data ingestion and processing.
- **frontend/**: Contains the React frontend application.
  - `src/`: React application source code.
  - `public/`: Static assets.

---

### Contributing

Contributions are welcome! Please fork the repository and submit a pull request with your changes. Ensure all code adheres to the style guide and includes proper documentation.

---

### License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for more details.

---

### Contact

For questions, feedback, or support, contact us at:

- **Email**: support@easyopendata.com

&&& FILE: ./backend\Dockerfile
&&& CONTENT:
# ./backend/Dockerfile
FROM python:3.10-slim

WORKDIR /app

COPY requirements.txt /app/requirements.txt
RUN pip install --no-cache-dir -r /app/requirements.txt

COPY . /app

CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000", "--reload"]


&&& FILE: ./backend\README.md
&&& CONTENT:
# EasyOpenData Backend

## Overview

The backend of EasyOpenData is a FastAPI application that serves as the core of the platform, handling data retrieval, processing, and API endpoints for the frontend application. It interacts with a PostGIS database to store and query spatial data.

---

## Key Components

- **FastAPI Application**: Provides RESTful APIs for data retrieval and processing.
- **PostGIS Database**: Stores spatial data and provides efficient spatial queries.
- **Data Ingestion Scripts**: Scripts to download, transform, and ingest data into the database.
- **Payment Processing**: Integration with Stripe API for handling payments.

---

## Setup Instructions

### Prerequisites

- **Docker** and **Docker Compose**
- **Python 3.10+**
- **GDAL** and **OGR** libraries
- **Conda** (optional, for managing environments)
- **Node.js** and **npm** (for gltf-pipeline)

### Running with Docker

The easiest way to run the backend is using Docker Compose.

#### Build and Run

```bash
docker-compose up --build
```

This will start the PostGIS database and the FastAPI backend.

#### Accessing the Backend API

- The backend API will be available at: [http://localhost:5400](http://localhost:5400)

### Manual Setup

If you prefer to run the backend without Docker, follow these steps.

#### 1. Create a Virtual Environment

Using Conda:

```bash
conda create -n easyopendata_env python=3.10
conda activate easyopendata_env
```

#### 2. Install Dependencies

Install GDAL and its libraries:

```bash
conda install -c conda-forge gdal libgdal
```

Install other dependencies:

```bash
pip install -r backend/requirements.txt
```

#### 3. Install gltf-pipeline

```bash
npm install -g gltf-pipeline
```

#### 4. Setup the Database

Ensure PostgreSQL and PostGIS are installed.

```bash
sudo apt install postgresql postgis
```

Create the database and extensions:

```sql
CREATE DATABASE easyopendata_database;
\c easyopendata_database;
CREATE EXTENSION postgis;
```

#### 5. Run Database Initialization Scripts

```bash
psql -U postgres -d easyopendata_database -f backend/db/init.sql
```

#### 6. Run the FastAPI Application

```bash
cd backend
uvicorn app.main:app --reload
```

---

## Data Ingestion

The `backend/ingestion` directory contains scripts to download and process data.

### Ingesting Data

1. **Navigate to the ingestion directory**

```bash
cd backend/ingestion
```

2. **Run the Ingestion Script**

The `bayern.py` script processes Meta4 files to download and ingest data.

```bash
python bayern.py
```

**Note**: Ensure you have the necessary Meta4 files in `data_sources/` and that you have adjusted the `META4_PATH` in the script.

### Requirements

- **lxml**
- **psycopg2**
- **GDAL/OGR** command-line tools (`ogr2ogr`)
- **pg2b3dm** executable (must be in `libs/`)

---

## Directory Structure

- **app/**: FastAPI application code.
  - `main.py`: Main application file.
  - `database.py`: Database connection setup.
  - `models.py`: Database models and Pydantic schemas.
  - `retrieve_geom.py`: Functions to retrieve and process geometries.

- **db/**: Database scripts.
  - `init.sql`: Database initialization script.
  - `index.sql`: Indexing script for the database.

- **ingestion/**: Data ingestion scripts.
  - `bayern.py`: Script to process and ingest data.
  - `data_sources/`: Directory containing Meta4 files.
  - `data_local/`: Directory where downloaded data will be stored.
  - `libs/`: Contains necessary executables like `pg2b3dm.exe`.

---

## API Endpoints

- **GET /**: Root endpoint to check if the backend is running.
- **POST /retrieve_obj**: Accepts a GeoJSON region and returns an OBJ file with the buildings within that region.
- **POST /create-payment-intent**: Creates a Stripe payment intent for processing payments.

---

## Environment Variables

- **DATABASE_URL**: The connection string for the PostGIS database.
- **STRIPE_API_KEY**: Your Stripe secret API key for payment processing.

---

## Payment Processing

The backend integrates with Stripe to handle payments. Ensure you have set your Stripe API keys in the environment variables.

---

## Contributing

Contributions are welcome! Please ensure any changes to the backend code are thoroughly tested.

---

## License

This project is licensed under the MIT License.

&&& FILE: ./backend\requirements.txt
&&& CONTENT:
fastapi
uvicorn[standard]
asyncpg
psycopg2-binary
sqlalchemy
geoalchemy2
# Additional dependencies
python-multipart
geojson
anyio
pydantic
packaging
redis
stripe
pyproj
lxml

&&& FILE: ./backend\app\database.py
&&& CONTENT:
import os
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
from sqlalchemy.orm import sessionmaker
from app.models import Base

DATABASE_URL = os.getenv('DATABASE_URL', 'postgresql+asyncpg://postgres:barcelona@localhost:8735/easyopendata_database')

engine = create_async_engine(DATABASE_URL, echo=True)
async_session = sessionmaker(
    bind=engine, class_=AsyncSession, expire_on_commit=False
)

# Function to create tables
async def init_db():
    async with engine.begin() as conn:
        await conn.run_sync(Base.metadata.create_all)



&&& FILE: ./backend\app\main.py
&&& CONTENT:
# ./backend/main.py

import asyncio
import tempfile
from typing import List
from urllib import request
import uuid
from fastapi import FastAPI, Depends, HTTPException
from pydantic import BaseModel
from sqlalchemy.ext.asyncio import AsyncSession
import stripe
from app.database import async_session, init_db
from app.models import Building, RegionRequest
from app.retrieve_geom import retrieve_obj_file
from sqlalchemy.future import select
from geoalchemy2.functions import ST_AsGeoJSON, ST_Intersects, ST_GeomFromText, ST_SimplifyPreserveTopology
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, FileResponse
import json
import math
import redis
import subprocess
import os
import logging
from fastapi.staticfiles import StaticFiles

import shutil

# Configure Logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI()


app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173", "https://easyopen.i-am-hellguz.uk", "https://easyopen-server.i-am-hellguz.uk"], 
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.on_event("startup")
async def on_startup():
    await init_db()

async def get_db():
    async with async_session() as session:
        yield session

@app.get("/")
async def read_root():
    return {"message": "Easy Open Data v1.0"}

@app.post("/retrieve_obj")
async def retrieve_obj(request: RegionRequest):
    print(f"Received region: {request.region}")

    try:
        # Generate a unique filename using UUID
        random_filename = f"{uuid.uuid4()}.obj"
        temp_path = os.path.join("/app/tempfiles", random_filename)
        await retrieve_obj_file(request.region, temp_path)
        return FileResponse(
            temp_path,
            media_type="application/octet-stream",
            filename=f"object.txt")
    except Exception as e:
        logger.error(f"Error in retrieve_obj: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


async def remove_temp_file(file_path: str):
    await asyncio.sleep(0)  # Ensure this runs after the response is sent
    if os.path.exists(file_path):
        os.unlink(file_path)

        
stripe.api_key = 'REMOVED_STRIPE_KEY'


def calculate_order_amount(amount: float):
    # Replace this constant with a calculation of the order's amount
    # Calculate the order total on the server to prevent
    # people from directly manipulating the amount on the client
    return int(amount*100)

class PaymentIntentRequest(BaseModel): 
    amount: float

@app.post("/create-payment-intent")
async def create_payment_intent(data: PaymentIntentRequest):
    try:
        intent = stripe.PaymentIntent.create(
            amount=calculate_order_amount(data.amount),  # Amount in cents
            currency="eur",
            automatic_payment_methods={"enabled": True},
        )
        return {"clientSecret": intent.client_secret}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
    
app.mount("/tileset", StaticFiles(directory="tileset"), name="tileset")


&&& FILE: ./backend\app\models.py
&&& CONTENT:
from sqlalchemy import Column, Integer, String
from sqlalchemy.ext.declarative import declarative_base
from geoalchemy2 import Geometry

Base = declarative_base()

class Building(Base):
    __tablename__ = 'building'

    gml_id = Column(String, primary_key=True)
    name = Column(String)
    geom = Column(Geometry('MULTIPOLYGONZ', srid=4326))  # Adjust geometry type as needed

from pydantic import BaseModel

class RegionRequest(BaseModel):
    region: dict  # Adjust the type if you have a more specific structure


&&& FILE: ./backend\app\retrieve_geom.py
&&& CONTENT:
# ./backend/retrieve_obj.py

import asyncio
import json
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.future import select
from geoalchemy2 import functions as func
from app.database import async_session
from app.models import Building
import os
from pyproj import Transformer

async def retrieve_obj_file(region_geojson, output_path):
    """
    Generates an OBJ file with buildings within the given polygon region.

    Args:
        region_geojson (dict): The GeoJSON representing the input region.
        output_path (str): The file path where the OBJ file will be saved.
    """
    # Parse the input GeoJSON to get the polygon geometry
    features = region_geojson.get('features', [])
    if not features:
        raise ValueError("No features found in the input GeoJSON.")
    
    polygon_feature = features[0]
    polygon_geometry = polygon_feature.get('geometry', {})
    if polygon_geometry.get('type') != 'Polygon':
        raise ValueError("The geometry must be of type 'Polygon'.")

    # Convert GeoJSON geometry to GeoJSON string
    polygon_geojson_str = json.dumps(polygon_geometry)

    # Choose the appropriate projection (e.g., UTM zone 32N for Germany)
    # You may need to adjust the EPSG code based on your location
    source_crs = 'EPSG:4326'  # WGS84 Latitude/Longitude
    target_crs = 'EPSG:25832'  # ETRS89 / UTM zone 32N (adjust as needed)

    # Create a Transformer object for coordinate transformation
    transformer = Transformer.from_crs(source_crs, target_crs, always_xy=True)

    # Start an asynchronous database session
    async with async_session() as session:
        # Query the database for buildings within the polygon
        stmt = select(
            Building.gml_id,
            func.ST_AsGeoJSON(Building.geom).label('geom_geojson')
        ).where(
            func.ST_Intersects(
                func.ST_MakeValid(Building.geom),
                func.ST_MakeValid(func.ST_GeomFromGeoJSON(polygon_geojson_str))
            )
        )
        
        result = await session.execute(stmt)
        buildings = result.fetchall()
        
        if not buildings:
            print("No buildings found within the given region.")
            return

        # Initialize lists to store OBJ data
        obj_vertices = []
        obj_faces = []
        vertex_offset = 0  # Offset for indexing vertices in faces

        # Process each building geometry
        for building in buildings:
            gml_id = building.gml_id
            geom_geojson_str = building.geom_geojson
            if not geom_geojson_str:
                continue  # Skip if geometry is null

            # Load geometry from GeoJSON
            geom_geojson = json.loads(geom_geojson_str)

            # Handle Polygon and MultiPolygon geometries
            geom_type = geom_geojson.get('type')
            coordinates = geom_geojson.get('coordinates')

            if geom_type == 'Polygon':
                polygons = [coordinates]
            elif geom_type == 'MultiPolygon':
                polygons = coordinates
            else:
                print(f"Skipping unsupported geometry type (ID: {gml_id}, Type: {geom_type})")
                continue

            for polygon in polygons:
                ring_vertex_indices = []

                # Process exterior ring
                exterior_coords = polygon[0]
                exterior_indices = []
                for coord in exterior_coords:
                    lon, lat = coord[:2]
                    z = coord[2] if len(coord) > 2 else 0
                    # Transform coordinates
                    x, y = transformer.transform(lon, lat)
                    obj_vertices.append(f"v {x} {z} {y}")
                    vertex_offset += 1
                    exterior_indices.append(vertex_offset)
                # Add face for exterior ring
                obj_faces.append(f"f {' '.join(map(str, exterior_indices))}")

                # Process interior rings (holes)
                for interior_coords in polygon[1:]:
                    interior_indices = []
                    for coord in interior_coords:
                        lon, lat = coord[:2]
                        z = coord[2] if len(coord) > 2 else 0
                        # Transform coordinates
                        x, y = transformer.transform(lon, lat)
                        obj_vertices.append(f"v {x} {z} {y}")
                        vertex_offset += 1
                        interior_indices.append(vertex_offset)
                    # Add face for interior ring (negative indices to denote holes are not standard in OBJ)
                    # Some software may not support holes directly
                    # So, we can skip adding faces for holes or handle them as separate objects
                    # For now, we'll skip adding faces for holes
                    print(f"Skipping interior ring (hole) in building ID: {gml_id}")

        # Write to OBJ file
        with open(output_path, 'w') as obj_file:
            obj_file.write("# OBJ file generated from buildings\n")
            obj_file.write("\n".join(obj_vertices))
            obj_file.write("\n")
            obj_file.write("\n".join(obj_faces))

        print(f"OBJ file successfully written to {output_path}")
        return


&&& FILE: ./backend\db\index.sql
&&& CONTENT:
-- Create the index if it doesn't exist
DO $$
BEGIN
    IF NOT EXISTS (
        SELECT 1 
        FROM pg_indexes 
        WHERE schemaname = 'public' 
        AND tablename = 'building' 
        AND indexname = 'buildings_geom_idx'
    ) THEN
        CREATE INDEX buildings_geom_idx ON building USING GIST(geom);
    END IF;
END $$;

-- Add the unique constraint if it doesn't exist
DO $$
BEGIN
    IF NOT EXISTS (
        SELECT 1 
        FROM pg_constraint 
        WHERE conname = 'gml_id_unique' 
        AND conrelid = 'public.building'::regclass
    ) THEN
        ALTER TABLE public.building ADD CONSTRAINT gml_id_unique UNIQUE (gml_id);
    END IF;
END $$;

-- Cluster the table using the index
CLUSTER building USING buildings_geom_idx;

-- Analyze to update statistics
ANALYZE building;


&&& FILE: ./backend\db\init.sql
&&& CONTENT:
-- Part 1: Database and extension creation (in transaction)
CREATE DATABASE easyopendata_database;
\c easyopendata_database;
CREATE EXTENSION IF NOT EXISTS postgis;

-- Part 2: System settings (must be outside transaction)
\connect easyopendata_database
\echo 'Setting system parameters...'

\set ON_ERROR_STOP off
ALTER SYSTEM SET maintenance_work_mem TO '1GB';
ALTER SYSTEM SET work_mem TO '256MB';
ALTER SYSTEM SET max_parallel_workers_per_gather TO 4;
\set ON_ERROR_STOP on



&&& FILE: ./backend\ingestion\bayern.py
&&& CONTENT:
#!/usr/bin/env python3
"""
process_meta4.py

A script to sequentially download GML files from a Meta4 file, transform them by embedding polygons,
ingest them into a PostgreSQL database, convert them to 3D tiles, and remove the original files.

Usage:
    python process_meta4.py file.meta4

Requirements:
    - Python 3.x
    - lxml
    - psycopg2
    - ogr2ogr (from GDAL)
    - pg2b3dm_new command available in PATH
"""

import sys
import os
import glob
import subprocess
import hashlib
import logging
import shutil
from urllib.parse import urlparse
from urllib.request import urlopen, Request
from urllib.error import URLError, HTTPError
from lxml import etree
import psycopg2

# Constants
META4_PATH = 'backend/ingestion/data_sources/munchen.meta4'
DATA_DIR = 'backend/ingestion/data_local/bayern'
DATABASE_URL = os.getenv('DATABASE_URL', 'postgresql://postgres:barcelona@localhost:8735/easyopendata_database')
CACHE_DIR = 'backend/tileset'
PG2B3DM_PATH = 'backend/ingestion/libs/pg2b3dm.exe'
SQL_INDEX_PATH = 'backend/db/index.sql'

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)

def parse_meta4(meta4_file):
    """
    Parses the Meta4 XML file and extracts file information.

    Args:
        meta4_file (str): Path to the Meta4 XML file.

    Returns:
        list of dict: List containing information about each file.
    """
    logging.info(f"Parsing Meta4 file: {meta4_file}")
    tree = etree.parse(meta4_file)
    root = tree.getroot()
    ns = {'metalink': 'urn:ietf:params:xml:ns:metalink'}

    files = []
    for file_elem in root.findall('metalink:file', namespaces=ns):
        name = file_elem.get('name')
        size = int(file_elem.find('metalink:size', namespaces=ns).text)
        hash_elem = file_elem.find('metalink:hash', namespaces=ns)
        hash_type = hash_elem.get('type')
        hash_value = hash_elem.text
        urls = [url_elem.text for url_elem in file_elem.findall('metalink:url', namespaces=ns)]
        files.append({
            'name': name,
            'size': size,
            'hash_type': hash_type,
            'hash_value': hash_value,
            'urls': urls
        })
    logging.info(f"Found {len(files)} files in Meta4.")
    return files

def download_file(url, dest_path):
    """
    Downloads a file from a URL to a destination path.

    Args:
        url (str): URL to download from.
        dest_path (str): Destination file path.

    Returns:
        bool: True if download was successful, False otherwise.
    """
    try:
        logging.info(f"Downloading from URL: {url}")
        headers = {'User-Agent': 'Mozilla/5.0'}
        req = Request(url, headers=headers)
        with urlopen(req) as response, open(dest_path, 'wb') as out_file:
            shutil.copyfileobj(response, out_file)
        logging.info(f"Downloaded file to: {dest_path}")
        return True
    except HTTPError as e:
        logging.warning(f"HTTP Error: {e.code} when downloading {url}")
    except URLError as e:
        logging.warning(f"URL Error: {e.reason} when downloading {url}")
    except Exception as e:
        logging.warning(f"Unexpected error when downloading {url}: {e}")
    return False

def verify_file(file_path, expected_size, expected_hash, hash_type='sha-256'):
    """
    Verifies the size and hash of a downloaded file.

    Args:
        file_path (str): Path to the file.
        expected_size (int): Expected file size in bytes.
        expected_hash (str): Expected hash value.
        hash_type (str): Hash algorithm, default 'sha-256'.

    Returns:
        bool: True if verification succeeds, False otherwise.
    """
    logging.info(f"Verifying file: {file_path}")
    # Check size
    actual_size = os.path.getsize(file_path)
    if actual_size != expected_size:
        logging.error(f"Size mismatch for {file_path}: expected {expected_size}, got {actual_size}")
        return False
    # Check hash
    hash_func = hashlib.new(hash_type)
    with open(file_path, 'rb') as f:
        for chunk in iter(lambda: f.read(8192), b''):
            hash_func.update(chunk)
    actual_hash = hash_func.hexdigest()
    if actual_hash.lower() != expected_hash.lower():
        logging.error(f"Hash mismatch for {file_path}: expected {expected_hash}, got {actual_hash}")
        return False
    logging.info(f"Verification passed for {file_path}")
    return True

def get_all_namespaces(gml_tree):
    """
    Extracts all namespaces from the GML tree and assigns a unique prefix to the default namespace.

    Args:
        gml_tree (etree.ElementTree): Parsed GML tree.

    Returns:
        dict: Namespace prefix to URI mapping.
    """
    nsmap = gml_tree.getroot().nsmap.copy()
    # Handle default namespace (None key)
    if None in nsmap:
        nsmap['default'] = nsmap.pop(None)
    # Ensure 'xlink' is included
    if 'xlink' not in nsmap:
        # Attempt to find the xlink namespace
        for prefix, uri in nsmap.items():
            if uri == 'http://www.w3.org/1999/xlink':
                nsmap['xlink'] = uri
                break
        else:
            # If not found, add it manually
            nsmap['xlink'] = 'http://www.w3.org/1999/xlink'
    return nsmap

def transform_gml(input_file, output_file):
    """
    Transforms the input GML file by embedding polygons into surfaceMember elements.

    Args:
        input_file (str): Path to the input GML file.
        output_file (str): Path to the output transformed GML file.
    """
    # Parse the GML file
    print(f"Parsing input GML file: {input_file}")
    parser = etree.XMLParser(remove_blank_text=True)
    tree = etree.parse(input_file, parser)
    root = tree.getroot()

    # Extract all namespaces
    namespaces = get_all_namespaces(tree)
    # print("Namespaces detected:")
    # for prefix, uri in namespaces.items():
    #     print(f"  Prefix: '{prefix}' => URI: '{uri}'")

    # Build a dictionary of gml:id to Polygon elements for quick lookup
    print("Indexing all <gml:Polygon> elements by gml:id...")
    polygon_dict = {}
    for polygon in root.xpath('.//gml:Polygon', namespaces=namespaces):
        polygon_id = polygon.get('{http://www.opengis.net/gml}id')
        if polygon_id:
            polygon_dict[polygon_id] = polygon
    print(f"Indexed {len(polygon_dict)} polygons.")

    # Find all <gml:surfaceMember> elements with xlink:href
    print("Finding all <gml:surfaceMember> elements with xlink:href...")
    surface_members = root.xpath('.//gml:surfaceMember[@xlink:href]', namespaces=namespaces)
    print(f"Found {len(surface_members)} <gml:surfaceMember> elements with xlink:href.")

    for sm in surface_members:
        href = sm.get('{http://www.w3.org/1999/xlink}href')
        if not href:
            continue
        # Extract the referenced polygon ID (remove the '#' prefix)
        polygon_id = href.lstrip('#')
        # print(f"Processing surfaceMember referencing Polygon ID: {polygon_id}")
        polygon = polygon_dict.get(polygon_id)
        if not polygon:
            print(f"Warning: Polygon with gml:id='{polygon_id}' not found. Skipping.")
            continue
        # Deep copy the polygon element
        polygon_copy = etree.fromstring(etree.tostring(polygon))
        # Remove any existing 'gml:id' to avoid duplicate IDs
        polygon_copy.attrib.pop('{http://www.opengis.net/gml}id', None)
        # Replace the surfaceMember's xlink:href attribute with the actual Polygon
        sm.clear()  # Remove existing children and attributes
        sm.append(polygon_copy)
        # print(f"Embedded Polygon ID: {polygon_id} into surfaceMember.")

    # Optionally, remove standalone <gml:Polygon> elements that were referenced
    # print("Removing standalone <gml:Polygon> elements that were referenced...")
    # removed_count = 0
    # for polygon_id in polygon_dict.keys():
    #     # Find and remove the standalone polygon
    #     polygons_to_remove = root.xpath(f'.//gml:Polygon[@gml:id="{polygon_id}"]', namespaces=namespaces)
    #     for polygon in polygons_to_remove:
    #         parent = polygon.getparent()
    #         if parent is not None:
    #             parent.remove(polygon)
    #             removed_count += 1
    #             print(f"Removed standalone Polygon ID: {polygon_id}.")
    # print(f"Removed {removed_count} standalone polygons.")

    # Write the transformed GML to the output file
    print(f"Writing transformed GML to: {output_file}")
    tree.write(output_file, pretty_print=True, xml_declaration=True, encoding='UTF-8')
    print("Transformation complete.")
def ingest_gml_file(gml_file, database_url):
    """
    Ingests a GML file into a PostgreSQL database using ogr2ogr.

    Args:
        gml_file (str): Path to the GML file.
        database_url (str): PostgreSQL connection URL.
    """
    logging.info(f"Ingesting GML file into database: {gml_file}")
    cmd = [
        'ogr2ogr',
        '-f', 'PostgreSQL',
        # '-overwrite',
        '-progress',
        '-lco', 'GEOMETRY_NAME=geom',
        '-skipfailures',
        '-nlt', 'MULTIPOLYGONZ',
        '-dim', 'XYZ',
        '-s_srs', 'EPSG:25832',
        '-t_srs', 'EPSG:4326',
        database_url,
        gml_file
    ]
    result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
    if result.returncode != 0:
        logging.error(f"ogr2ogr failed for {gml_file}: {result.stderr}")
        raise RuntimeError(f"ogr2ogr failed: {result.stderr}")
    logging.info(f"Ingested {gml_file} into database successfully.")

def execute_sql_file(sql_file_path, database_url):
    """Executes a SQL file in the database."""
    logging.info(f"Executing SQL file: {sql_file_path}")
    url = urlparse(database_url)
    conn = psycopg2.connect(
        dbname=url.path[1:],
        user=url.username,
        password=url.password,
        host=url.hostname,
        port=url.port
    )
    try:
        with conn.cursor() as cur:
            with open(sql_file_path, 'r') as f:
                cur.execute(f.read())
            conn.commit()
        logging.info("SQL file executed successfully")
    except Exception as e:
        logging.error(f"Failed to execute SQL file: {e}")
        conn.rollback()
        raise
    finally:
        conn.close()

def put_buildings_on_ground(database_url):
    """
    Updates the geometries in the 'building' table to put them on ground level.

    Args:
        database_url (str): PostgreSQL connection URL.
    """
    logging.info("Updating building geometries to ground level.")
    url = urlparse(database_url)
    conn = psycopg2.connect(
        dbname=url.path[1:],
        user=url.username,
        password=url.password,
        host=url.hostname,
        port=url.port
    )
    try:
        with conn.cursor() as cur:
            cur.execute("""
                UPDATE building
                SET geom = ST_Translate(geom, 0, 0, -ST_ZMin(geom))
                WHERE ST_ZMin(geom) != 0;
            """)
            conn.commit()
            logging.info("Building geometries updated successfully.")
    except Exception as e:
        logging.error(f"Failed to update building geometries: {e}")
        conn.rollback()
        raise
    finally:
        conn.close()

def convert_to_3d_tiles(cache_dir, database_url):
    """
    Converts buildings from the database to 3D tiles using pg2b3dm.

    Args:
        cache_dir (str): Output directory for 3D tiles.
        database_url (str): PostgreSQL connection URL.
    """
    logging.info("Converting buildings to 3D tiles with pg2b3dm.")
    # Parse the database URL for parameters
    url = urlparse(database_url)
    dbname = url.path[1:]
    user = url.username
    host = url.hostname or 'localhost'
    port=url.port
    # Assume password is handled via environment or .pgpass
    cmd = [
        PG2B3DM_PATH,
        '-h', f"{host}:{port}",
        '-U', user,
        '-c', 'geom',
        '-t', 'building',
        '-d', dbname,
        '-o', cache_dir, 
        # '--use_implicit_tiling', 'false'
    ]
    # To handle password, set PGPASSWORD environment variable if available
    env = os.environ.copy()
    if url.password:
        env['PGPASSWORD'] = url.password
    result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, env=env)
    if result.returncode != 0:
        logging.error(f"pg2b3dm failed: {result.stderr}")
        raise RuntimeError(f"pg2b3dm failed: {result.stderr}")
    logging.info("3D tiles generated successfully.")

def apply_draco_compression(cache_dir):
    logging.info("Applying Draco compression to glTF files.")
    for root, dirs, files in os.walk(cache_dir):
        for file in files:
            if file.endswith('.glb'):
                gltf_file = os.path.join(root, file)

                # Check if the first line of the file contains "draco"
                try:
                    with open(gltf_file, 'rb') as f:
                        first_line = f.readline().decode('utf-8', errors='ignore')
                        if "draco" in first_line.lower():
                            logging.info(f"File {gltf_file} already contains Draco; skipping compression.")
                            continue
                except Exception as e:
                    logging.error(f"Error reading file {gltf_file}: {e}")
                    continue

                # Proceed with Draco compression
                compressed_file = os.path.join(root, f"{os.path.splitext(file)[0]}_draco.glb")
                cmd = [
                    "gltf-pipeline",
                    '-i', gltf_file,
                    '-o', compressed_file,
                    '--draco.compressionLevel', '7'
                ]
                print(" ".join(cmd))
                result = subprocess.run(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
                if result.returncode != 0:
                    logging.error(f"Draco compression failed for {gltf_file}: {result.stderr}")
                else:
                    os.replace(compressed_file, gltf_file)
                    logging.info(f"Applied Draco compression to {gltf_file}")

def remove_file(file_path):
    """
    Removes a file from the filesystem.

    Args:
        file_path (str): Path to the file.
    """
    try:
        os.remove(file_path)
        logging.info(f"Removed file: {file_path}")
    except OSError as e:
        logging.warning(f"Failed to remove file {file_path}: {e}")

def main(meta4_file):
    
    # Ensure DATA_DIR exists
    os.makedirs(DATA_DIR, exist_ok=True)
    os.makedirs(CACHE_DIR, exist_ok=True)

    # Parse the Meta4 file
    files = parse_meta4(meta4_file)

    for ix, file_info in enumerate(files, start=1):
        file_name = file_info['name']
        size = file_info['size']
        hash_type = file_info['hash_type']
        hash_value = file_info['hash_value']
        urls = file_info['urls']

        logging.info(f"‚ñ∂Ô∏è   FILE {ix}/{len(files)}")
        logging.info(f"Processing file: {file_name}")

        # Determine download paths
        download_path = os.path.join(DATA_DIR, file_name)
        transformed_file_name = os.path.splitext(file_name)[0] + '_trs.gml'
        transformed_path = os.path.join(DATA_DIR, transformed_file_name)

        # Download the file from available URLs
        downloaded = False
        for url in urls:
            if download_file(url, download_path):
                # Verify the file
                if verify_file(download_path, size, hash_value, hash_type):
                    downloaded = True
                    break
                else:
                    logging.warning(f"Verification failed for {download_path}. Trying next URL.")
                    remove_file(download_path)
        if not downloaded:
            logging.error(f"Failed to download and verify {file_name} from all URLs. Skipping.")
            continue

        try:
            # Transform the GML file
            transform_gml(download_path, transformed_path)

            # Ingest the transformed GML into the database
            ingest_gml_file(transformed_path, DATABASE_URL)

            # Execute the SQL file after first ingestion
            if ix == 1:  # Only after first file
                execute_sql_file(SQL_INDEX_PATH, DATABASE_URL)

            # Update building geometries
            put_buildings_on_ground(DATABASE_URL)

            # Convert to 3D tiles
            if (ix-1) % 20 == 0:
                convert_to_3d_tiles(CACHE_DIR, DATABASE_URL)
                apply_draco_compression(CACHE_DIR)

            # Remove the transformed GML file
            remove_file(transformed_path)
            # Remove the transformed GFS file
            remove_file(transformed_path.split(".")[0] + ".gfs")

            # Optionally, remove the original downloaded GML file
            remove_file(download_path)

            logging.info(f"Completed processing for {file_name}")

        except Exception as e:
            logging.error(f"An error occurred while processing {file_name}: {e}")
            # Optionally, clean up files or continue
            continue

    logging.info("All files processed.")

if __name__ == '__main__':
    meta4_file = META4_PATH
    if not os.path.isfile(meta4_file):
        logging.error(f"Meta4 file '{meta4_file}' does not exist.")
        sys.exit(1)
    main(meta4_file)


&&& FILE: ./backend\ingestion\README.md
&&& CONTENT:
# EasyOpenData Data Ingestion

## Overview

The `ingestion` directory contains scripts and resources for downloading, transforming, and ingesting 3D building data into the PostGIS database. It also includes tools for generating 3D tilesets from the database.

---

## Setup Instructions

### Prerequisites

- **Conda** (optional, for managing Python environments)
- **GDAL** and **OGR** libraries
- **Python 3.x**
- **Node.js** and **npm** (for `gltf-pipeline`)

### Steps

#### 1. Create a Conda Environment (Optional)

```bash
conda create -n easyopendata_env python=3.10
conda activate easyopendata_env
```

#### 2. Install GDAL and Libraries

```bash
conda install -c conda-forge gdal libgdal
```

#### 3. Install Python Dependencies

```bash
pip install -r ../../requirements.txt
```

#### 4. Install gltf-pipeline

```bash
npm install -g gltf-pipeline
```

---

## Data Ingestion Scripts

### `bayern.py`

This script sequentially downloads GML files from a Meta4 file, transforms them by embedding polygons, ingests them into a PostgreSQL database, converts them to 3D tiles, and removes the original files.

#### Usage

```bash
python bayern.py
```

#### Notes

- Ensure that the `META4_PATH` variable in the script points to a valid `.meta4` file in the `data_sources/` directory.
- The script requires the `pg2b3dm.exe` executable to be present in the `libs/` directory.

### Directory Structure

- **data_sources/**: Contains `.meta4` files that list the URLs of GML data to download.
- **data_local/**: Directory where downloaded GML files are stored temporarily.
- **libs/**: Contains necessary executables like `pg2b3dm.exe`.

---

## Additional Information

- **GDAL/OGR**: Used for converting and ingesting GML files into PostGIS.
- **pg2b3dm**: Tool for converting PostGIS data into 3D tiles compatible with CesiumJS.
- **gltf-pipeline**: Used for optimizing and compressing glTF files.

---

## Tips

- **Error Handling**: The scripts include logging to help diagnose issues during the ingestion process.
- **Performance**: Adjust database settings in `init.sql` and `index.sql` for better performance during bulk data ingestion.

---

## Contributing

Contributions to improve data ingestion scripts are welcome. Please ensure that any new scripts or changes are well-documented and tested.

---

## License

This project is licensed under the MIT License.

&&& FILE: ./backend\ingestion\data_local\bayern\582_5530.gml
&&& CONTENT:
<?xml version="1.0" encoding="UTF-8"?>
<CityModel xmlns:tex="http://www.opengis.net/citygml/texturedsurface/1.0" xmlns:sch="http://www.ascc.net/xml/schematron" xmlns:veg="http://www.opengis.net/citygm
................................

&&& FILE: ./backend\ingestion\data_local\bayern\582_5530_trs.gfs
&&& CONTENT:
<GMLFeatureClassList>
  <GMLFeatureClass>
    <Name>Building</Name>
    <ElementPath>Building</ElementPath>
    <GeometryName>lod2Solid</GeometryName>
    <GeometryElementPath>lod2Solid</GeometryEleme
................................

&&& FILE: ./backend\ingestion\data_local\bayern\582_5530_trs.gml
&&& CONTENT:
<?xml version='1.0' encoding='UTF-8'?>
<CityModel xmlns:tex="http://www.opengis.net/citygml/texturedsurface/1.0" xmlns:sch="http://www.ascc.net/xml/schematron" xmlns:veg="http://www.opengis.net/citygm
................................

&&& FILE: ./backend\ingestion\data_local\bayern\654_5310.gml
&&& CONTENT:
<?xml version="1.0" encoding="UTF-8"?>
<CityModel xmlns:tex="http://www.opengis.net/citygml/texturedsurface/1.0" xmlns:sch="http://www.ascc.net/xml/schematron" xmlns:veg="http://www.opengis.net/citygm
................................

&&& FILE: ./backend\ingestion\data_local\bayern\654_5310_trs.gfs
&&& CONTENT:
<GMLFeatureClassList>
  <GMLFeatureClass>
    <Name>Building</Name>
    <ElementPath>Building</ElementPath>
    <GeometryName>lod2Solid</GeometryName>
    <GeometryElementPath>lod2Solid</GeometryEleme
................................

&&& FILE: ./backend\ingestion\data_local\bayern\654_5310_trs.gml
&&& CONTENT:
<?xml version='1.0' encoding='UTF-8'?>
<CityModel xmlns:tex="http://www.opengis.net/citygml/texturedsurface/1.0" xmlns:sch="http://www.ascc.net/xml/schematron" xmlns:veg="http://www.opengis.net/citygm
................................

&&& FILE: ./backend\ingestion\data_local\bayern\680_5336.gml
&&& CONTENT:
<?xml version="1.0" encoding="UTF-8"?>
<CityModel xmlns:tex="http://www.opengis.net/citygml/texturedsurface/1.0" xmlns:sch="http://www.ascc.net/xml/schematron" xmlns:veg="http://www.opengis.net/citygm
................................

&&& FILE: ./backend\ingestion\data_sources\bamberg.meta4
&&& CONTENT:
<?xml version="1.0" encoding="UTF-8"?>
<metalink xmlns="urn:ietf:params:xml:ns:metalink">
  <generator>BVV-MetaLinker</generator>
  <published>2024-11-26T22:13:07Z</published>
  <file name="636_5524.g
................................

&&& FILE: ./backend\ingestion\data_sources\bayern.meta4
&&& CONTENT:
<?xml version="1.0" encoding="UTF-8"?>
<metalink xmlns="urn:ietf:params:xml:ns:metalink">
  <generator>BVV-MetaLinker</generator>
  <published>2024-11-19T22:09:01Z</published>
  <file name="792_5432.g
................................

&&& FILE: ./backend\ingestion\data_sources\munchen.meta4
&&& CONTENT:
<?xml version="1.0" encoding="UTF-8"?>
<metalink xmlns="urn:ietf:params:xml:ns:metalink">
  <generator>BVV-MetaLinker</generator>
  <published>2024-11-19T22:08:58Z</published>
  <file name="680_5342.g
................................

&&& FILE: ./backend\ingestion\libs\pg2b3dm.exe
&&& ERROR: Could not read file: 'utf-8' codec can't decode byte 0x90 in position 2: invalid start byte

&&& FILE: ./backend\tempfiles\0ebaef62-302b-4cb5-b7db-c83d53020ba2.obj
&&& CONTENT:
# OBJ file generated from buildings
v 692466.2220121699 0 5334731.421954182
v 692466.2220121699 11.428 5334731.421954182
v 692465.9520113174 11.428 5334728.848945844
v 692465.9520113174 0 5334728.8489
................................

&&& FILE: ./backend\tempfiles\13bbe29e-46f0-494e-afde-b7e48d2a2b2e.obj
&&& CONTENT:
# OBJ file generated from buildings
v 680567.9310030596 3.508 5342543.4299777085
v 680566.789971829 3.508 5342543.155011388
v 680566.789971829 0 5342543.155011388
v 680567.9310030596 0 5342543.4299777
................................

&&& FILE: ./backend\tempfiles\1fc79dc8-42f6-40ed-9d9c-1da5b48f3473.obj
&&& CONTENT:
# OBJ file generated from buildings


................................

&&& FILE: ./backend\tempfiles\2a394fde-a09c-42ba-8168-890445a45cd7.obj
&&& CONTENT:
# OBJ file generated from buildings
v 684244.8699987399 0 5343079.640031528
v 684244.8699987399 13.263 5343079.640031528
v 684225.6209640335 14.26 5343077.449997416
v 684206.369987038 13.263 5343075.2
................................

&&& FILE: ./backend\tempfiles\37627956-7228-462d-98f8-fbba26605ef0.obj
&&& CONTENT:
# OBJ file generated from buildings


................................

&&& FILE: ./backend\tempfiles\3772f021-baeb-4916-bbfc-e1884f54c094.obj
&&& CONTENT:
# OBJ file generated from buildings
v 681044.1539687354 0 5343742.204972287
v 681044.1539687354 5.777 5343742.204972287
v 680992.2840366996 5.767 5343747.450959618
v 680992.2840366996 0 5343747.450959
................................

&&& FILE: ./backend\tempfiles\4e147667-b8f6-4a58-b874-087dde71f6f4.obj
&&& CONTENT:
# OBJ file generated from buildings
v 692346.1879965623 16.396 5334621.376947997
v 692346.1879965623 0 5334621.376947997
v 692346.8869687994 0 5334625.6130508045
v 692347.093996431 0 5334626.878050981
................................

&&& FILE: ./backend\tempfiles\518a4dc0-1821-4990-b379-54b833b598fd.obj
&&& CONTENT:
# OBJ file generated from buildings
v 692009.9379970876 4.357 5334359.5610187
v 692012.5230037409 4.358 5334359.49202265
v 692015.0539863509 4.468 5334358.949020741
v 692015.5209730046 4.488 5334358.8
................................

&&& FILE: ./backend\tempfiles\538f2ac5-4ed3-43dc-ae34-9736446f0ed8.obj
&&& CONTENT:
# OBJ file generated from buildings
v 684129.4400338647 0 5342679.989994051
v 684113.7999785779 0 5342676.399946041
v 684113.7999785779 5.154 5342676.399946041
v 684128.9959698505 5.154 5342679.887993
................................

&&& FILE: ./backend\tempfiles\5fcd10c0-8110-479c-9425-b813eaf33866.obj
&&& CONTENT:
# OBJ file generated from buildings
v 687793.1499662541 3.116 5330409.703961996
v 687791.8770091551 3.116 5330414.617998084
v 687791.8770091551 0 5330414.617998084
v 687793.1499662541 0 5330409.703961
................................

&&& FILE: ./backend\tempfiles\75530f8b-fe84-471c-ae5f-997e8629a7e4.obj
&&& CONTENT:
# OBJ file generated from buildings


................................

&&& FILE: ./backend\tempfiles\77c12452-c4ee-46c3-b5f1-0db94727d43e.obj
&&& CONTENT:
# OBJ file generated from buildings


................................

&&& FILE: ./backend\tempfiles\8e15ee79-8a7a-4fdd-a135-3a4b0e2cba44.obj
&&& CONTENT:
# OBJ file generated from buildings
v 687629.5080292135 12.24 5330674.962039919
v 687633.8260145726 10.65 5330675.627970491
v 687633.8260145726 12.76 5330675.627970491
v 687631.4249967044 12.76 533067
................................

&&& FILE: ./backend\tempfiles\8e80c443-cfcd-467c-9feb-92bf2e18b6da.obj
&&& CONTENT:
# OBJ file generated from buildings
v 692818.6949864172 0 5335090.412017974
v 692819.3910307497 0 5335094.381968065
v 692824.4699776318 0 5335093.477968954
v 692823.7550192552 0 5335089.497032916
v 69
................................

&&& FILE: ./backend\tempfiles\df087d27-ace5-4504-bdd4-65f981e3f26a.obj
&&& CONTENT:
# OBJ file generated from buildings
v 692160.4799965809 0 5334348.86996756
v 692160.4799965809 5.697 5334348.86996756
v 692161.110030973 5.697 5334349.080054309
v 692161.110030973 0 5334349.080054309

................................

&&& FILE: ./backend\tempfiles\fb2d0100-cbec-472c-b7a0-79fcf0e674ea.obj
&&& CONTENT:
# OBJ file generated from buildings


................................

&&& FILE: ./frontend\.env
&&& CONTENT:
HTTPS=true

&&& FILE: ./frontend\.gitignore
&&& CONTENT:
# Logs
logs
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*
pnpm-debug.log*
lerna-debug.log*

node_modules
dist
dist-ssr
*.local

# Editor directories and files
.vscode/*
!.vscode/extensions.json
.idea
.DS_Store
*.suo
*.ntvs*
*.njsproj
*.sln
*.sw?

yarn.lock

&&& FILE: ./frontend\Dockerfile
&&& CONTENT:
FROM node:18-alpine

WORKDIR /app

# Copy package.json and yarn.lock first for dependency installation
COPY package.json ./

# Install dependencies
RUN yarn install 

# Copy the rest of the frontend code
COPY . .

EXPOSE 5173

CMD ["yarn", "dev", "--host", "0.0.0.0"]

&&& FILE: ./frontend\eslint.config.js
&&& CONTENT:
import js from '@eslint/js'
import globals from 'globals'
import react from 'eslint-plugin-react'
import reactHooks from 'eslint-plugin-react-hooks'
import reactRefresh from 'eslint-plugin-react-refresh'

export default [
  { ignores: ['dist'] },
  {
    files: ['**/*.{js,jsx}'],
    languageOptions: {
      ecmaVersion: 2020,
      globals: globals.browser,
      parserOptions: {
        ecmaVersion: 'latest',
        ecmaFeatures: { jsx: true },
        sourceType: 'module',
      },
    },
    settings: { react: { version: '18.3' } },
    plugins: {
      react,
      'react-hooks': reactHooks,
      'react-refresh': reactRefresh,
    },
    rules: {
      ...js.configs.recommended.rules,
      ...react.configs.recommended.rules,
      ...react.configs['jsx-runtime'].rules,
      ...reactHooks.configs.recommended.rules,
      'react/jsx-no-target-blank': 'off',
      'react-refresh/only-export-components': [
        'warn',
        { allowConstantExport: true },
      ],
    },
  },
]


&&& FILE: ./frontend\index.html
&&& CONTENT:
<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <title>EasyOpenData</title>

  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link href="https://api.mapbox.com/mapbox-gl-js/v2.6.1/mapbox-gl.css" rel="stylesheet">
  <link rel="stylesheet" href="https://api.mapbox.com/mapbox-gl-js/plugins/mapbox-gl-draw/v1.3.0/mapbox-gl-draw.css"
    type="text/css">

  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
</head>

<body>
</body>
<script type="module" src="./src/App.tsx"></script>

</html>

&&& FILE: ./frontend\package.json
&&& CONTENT:
{
  "name": "frontend",
  "private": true,
  "version": "0.0.0",
  "type": "module",
  "scripts": {
    "dev": "vite",
    "build": "vite build",
    "lint": "eslint .",
    "preview": "vite preview"

................................

&&& FILE: ./frontend\README.md
&&& CONTENT:
# EasyOpenData Frontend

## Overview

The frontend of EasyOpenData is a React application that provides an interactive map interface for users to select areas of interest, choose data layers, and download spatial data. It integrates with the backend API and handles payment processing via Stripe.

---

## Key Features

- **Interactive Map Interface**: Built with React and MapLibre GL JS for map rendering.
- **Drawing Tools**: Allows users to draw polygons to select regions.
- **3D Visualization**: Uses Deck.gl to render 3D buildings.
- **Search Functionality**: Integrated with Nominatim for location search.
- **Payment Processing**: Secure payments via Stripe.
- **Responsive Design**: Adapts to mobile and desktop screens.

---

## Setup Instructions

### Prerequisites

- **Node.js** and **npm** or **yarn**

### Installation

1. **Install Dependencies**

```bash
cd frontend
yarn install
# or
npm install
```

### Running the Development Server

```bash
yarn dev
# or
npm run dev
```

The application will be available at [http://localhost:5173](http://localhost:5173)

### Build for Production

```bash
yarn build
# or
npm run build
```

The production build will be in the `dist/` directory.

---

## Configuration

### Environment Variables

Create a `.env` file in the `frontend` directory to set environment variables.

- **VITE_BACKEND_URL**: The URL of the backend API.

Example `.env` file:

```
VITE_BACKEND_URL=http://localhost:5400
```

### Map Style

The map uses a custom style defined in `src/basemap.json`. You can customize the map style by modifying this file or replacing it with another style.

---

## Project Structure

- **src/**: Contains the source code of the React application.
  - `App.tsx`: Main application component.
  - `CheckoutForm.tsx`: Handles payment form and Stripe integration.
  - `FloatingPanel.tsx`: UI component for user interactions.
  - `Legals.tsx`: Displays legal documents.
  - `draw-control.ts`: Custom control for drawing polygons.
  - `basemap.json`: Custom map style.

- **public/**: Contains static assets.

---

## Key Components

- **Map Integration**: Uses MapLibre GL JS for map rendering and Mapbox Draw for drawing tools.
- **3D Rendering**: Deck.gl is used to render 3D buildings.
- **Payment Integration**: Stripe is integrated using `@stripe/react-stripe-js` and `@stripe/stripe-js`.
- **Legal Documents**: Legal documents are displayed using `ReactMarkdown`.

---

## Customization

- **Map Style**: Modify `src/basemap.json` to change the map appearance.
- **API Endpoints**: Ensure `VITE_BACKEND_URL` points to the correct backend API.
- **Stripe Keys**: Update the publishable key in `FloatingPanel.tsx` and ensure the backend has the correct secret key.

---

## Legal Documents

The `docs/` directory contains Markdown files for legal documents such as:

- `agb.md`: Terms and Conditions
- `datenschutz.md`: Privacy Policy
- `impressum.md`: Imprint
- `widerruf.md`: Cancellation Policy

These documents are displayed in the application using the `Legals.tsx` component.

---

## Contributing

Contributions are welcome! Please ensure any changes to the frontend code are thoroughly tested.

---

## License

This project is licensed under the MIT License.

&&& FILE: ./frontend\tsconfig.json
&&& CONTENT:
{
    "compilerOptions": {
      "target": "es2020",
      "jsx": "react",
      "moduleResolution": "node",
      "allowSyntheticDefaultImports": true
    }
  }
................................

&&& FILE: ./frontend\vite.config.js
&&& CONTENT:
import { defineConfig } from 'vite'
import react from '@vitejs/plugin-react'

// https://vite.dev/config/
export default defineConfig({
  server: {
    watch: {
      usePolling: true, // For Docker environments
    },
  },
  plugins: [react()],
})


&&& FILE: ./frontend\yarn.lock
&&& CONTENT:
# THIS IS AN AUTOGENERATED FILE. DO NOT EDIT THIS FILE DIRECTLY.
# yarn lockfile v1


"@ampproject/remapping@^2.2.0":
  version "2.3.0"
  resolved "https://registry.npmjs.org/@ampproject/remapping/-/r
................................

&&& FILE: ./frontend\public\vite.svg
&&& CONTENT:
<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="iconify iconify--logos" width="31.88" height="32" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 257"><defs><linearGradient id="IconifyId1813088fe1fbc01fb466" x1="-.828%" x2="57.636%" y1="7.652%" y2="78.411%"><stop offset="0%" stop-color="#41D1FF"></stop><stop offset="100%" stop-color="#BD34FE"></stop></linearGradient><linearGradient id="IconifyId1813088fe1fbc01fb467" x1="43.376%" x2="50.316%" y1="2.242%" y2="89.03%"><stop offset="0%" stop-color="#FFEA83"></stop><stop offset="8.333%" stop-color="#FFDD35"></stop><stop offset="100%" stop-color="#FFA800"></stop></linearGradient></defs><path fill="url(#IconifyId1813088fe1fbc01fb466)" d="M255.153 37.938L134.897 252.976c-2.483 4.44-8.862 4.466-11.382.048L.875 37.958c-2.746-4.814 1.371-10.646 6.827-9.67l120.385 21.517a6.537 6.537 0 0 0 2.322-.004l117.867-21.483c5.438-.991 9.574 4.796 6.877 9.62Z"></path><path fill="url(#IconifyId1813088fe1fbc01fb467)" d="M185.432.063L96.44 17.501a3.268 3.268 0 0 0-2.634 3.014l-5.474 92.456a3.268 3.268 0 0 0 3.997 3.378l24.777-5.718c2.318-.535 4.413 1.507 3.936 3.838l-7.361 36.047c-.495 2.426 1.782 4.5 4.151 3.78l15.304-4.649c2.372-.72 4.652 1.36 4.15 3.788l-11.698 56.621c-.732 3.542 3.979 5.473 5.943 2.437l1.313-2.028l72.516-144.72c1.215-2.423-.88-5.186-3.54-4.672l-25.505 4.922c-2.396.462-4.435-1.77-3.759-4.114l16.646-57.705c.677-2.35-1.37-4.583-3.769-4.113Z"></path></svg>

&&& FILE: ./frontend\src\App.css
&&& CONTENT:
@import url('https://fonts.googleapis.com/css2?family=IBM+Plex+Sans:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&display=swap');
body,
#root {
    margin: 0;
    width: 100vw;
    height: 100vh;
    overflow: hidden;
}

/* Override all fonts */
* {
    font-family: 'IBM Plex Sans', sans-serif;
}
.ibm-plex-sans-thin {
    font-family: "IBM Plex Sans", sans-serif;
    font-weight: 100;
    font-style: normal;
  }
  
  .ibm-plex-sans-extralight {
    font-family: "IBM Plex Sans", sans-serif;
    font-weight: 200;
    font-style: normal;
  }
  
  .ibm-plex-sans-light {
    font-family: "IBM Plex Sans", sans-serif;
    font-weight: 300;
    font-style: normal;
  }
  
  .ibm-plex-sans-regular {
    font-family: "IBM Plex Sans", sans-serif;
    font-weight: 400;
    font-style: normal;
  }
  
  .ibm-plex-sans-medium {
    font-family: "IBM Plex Sans", sans-serif;
    font-weight: 500;
    font-style: normal;
  }
  
  .ibm-plex-sans-semibold {
    font-family: "IBM Plex Sans", sans-serif;
    font-weight: 600;
    font-style: normal;
  }
  
  .ibm-plex-sans-bold {
    font-family: "IBM Plex Sans", sans-serif;
    font-weight: 700;
    font-style: normal;
  }
  
  .ibm-plex-sans-thin-italic {
    font-family: "IBM Plex Sans", sans-serif;
    font-weight: 100;
    font-style: italic;
  }
  
  .ibm-plex-sans-extralight-italic {
    font-family: "IBM Plex Sans", sans-serif;
    font-weight: 200;
    font-style: italic;
  }
  
  .ibm-plex-sans-light-italic {
    font-family: "IBM Plex Sans", sans-serif;
    font-weight: 300;
    font-style: italic;
  }
  
  .ibm-plex-sans-regular-italic {
    font-family: "IBM Plex Sans", sans-serif;
    font-weight: 400;
    font-style: italic;
  }
  
  .ibm-plex-sans-medium-italic {
    font-family: "IBM Plex Sans", sans-serif;
    font-weight: 500;
    font-style: italic;
  }
  
  .ibm-plex-sans-semibold-italic {
    font-family: "IBM Plex Sans", sans-serif;
    font-weight: 600;
    font-style: italic;
  }
  
  .ibm-plex-sans-bold-italic {
    font-family: "IBM Plex Sans", sans-serif;
    font-weight: 700;
    font-style: italic;
  }
  

&&& FILE: ./frontend\src\App.tsx
&&& CONTENT:
// Root.tsx
import React, { useCallback, useState, useRef, useEffect } from "react";
import { createRoot } from "react-dom/client";
import {
  Map,
  NavigationControl,
  Popup,
  useControl,
} from "react-map-gl/maplibre";
import { Tile3DLayer, MapViewState, AmbientLight, DirectionalLight, LightingEffect } from "deck.gl";
import { MapboxOverlay as DeckOverlay } from "@deck.gl/mapbox";
import "maplibre-gl/dist/maplibre-gl.css";
import type { Tileset3D } from "@loaders.gl/tiles";
import MapboxDraw from "@mapbox/mapbox-gl-draw";
import "@mapbox/mapbox-gl-draw/dist/mapbox-gl-draw.css";
import FloatingPanel from "./FloatingPanel";
import * as turf from "@turf/turf";
import "bootstrap/dist/css/bootstrap.min.css";

import DrawControl from './draw-control';
import LegalDocuments from "./Legals";

import './App.css'

const BACKEND_URL = import.meta.env.VITE_BACKEND_URL
const TILESET_URL = BACKEND_URL + '/tileset/tileset.json';

const INITIAL_VIEW_STATE: MapViewState = { 
  latitude: 48.1351,
  longitude: 11.5820,
  pitch: 45, 
  maxPitch: 60,
  bearing: 0,
  minZoom: 2,
  maxZoom: 30,
  zoom: 15,
};

const MAP_STYLE = "./src/basemap.json";

function DeckGLOverlay(props: any) {
  const overlay = useControl(() => new DeckOverlay(props));
  overlay.setProps(props);
  return null;
}

function Root() {
  const [selected, setSelected] = useState<any>(null);
  const [viewState, setViewState] = useState<MapViewState>(INITIAL_VIEW_STATE);
  const [features, setFeatures] = useState<Record<string, any>>({});
  const [isLod2Visible, setIsLod2Visible] = useState(true);
  const [polygonArea, setPolygonArea] = useState<number | null>(null);
  const mapRef = useRef<any>(null); // Reference to the map instance

  const drawRef = useRef<MapboxDraw | null>(null); // Reference to the MapboxDraw instance

  // Initialize MapboxDraw and add it to the map
  const handleMapLoad = useCallback(() => {
    const map = mapRef.current.getMap();

    // Initialize MapboxDraw if not already initialized
    if (!drawRef.current) {
      drawRef.current = new MapboxDraw({
        displayControlsDefault: false,
        controls: {
          polygon: false,
          trash: false,
        },
      });
      map.addControl(drawRef.current);
    }
  }, []);
  const onTilesetLoad = (tileset: Tileset3D) => {
    const { cartographicCenter, zoom } = tileset;
    setViewState((prev) => ({
      ...prev,
      longitude: cartographicCenter[0],
      latitude: cartographicCenter[1],
      zoom,
    }));
  };

  onTileLoad: (tile) => {
    tile.content.traverse((object) => {
      if (object.isMesh) {
        // Adjust colors if needed
        object.material.color.setHex(0xffffff);
      }
    });
  }

  const onUpdate = useCallback((e) => {
    setFeatures((currFeatures) => {
      const newFeatures = { ...currFeatures };
      for (const f of e.features) {
        newFeatures[f.id] = f;
      }
      return newFeatures;
    });

    // Calculate polygon area
    if (e.features && e.features.length > 0) {
      const polygon = e.features[0];
      const area = turf.area(polygon) / 1e6; // Convert from m¬≤ to km¬≤
      setPolygonArea(area);
    }
  }, []);

  const onDelete = useCallback((e) => {
    setFeatures((currFeatures) => {
      const newFeatures = { ...currFeatures };
      for (const f of e.features) {
        delete newFeatures[f.id];
      }
      return newFeatures;
    });
    setPolygonArea(null);
  }, []);

  const handleDrawPolygon = () => {
    if (drawRef.current) {
      drawRef.current.deleteAll();
      drawRef.current.changeMode("draw_polygon");
    }
  };

  const handleRemovePolygon = () => {
    if (drawRef.current) {
      drawRef.current.deleteAll();
    }
  };

  const handleFetchObjFile = async () => {
    console.info("getFetchObjFile")
    if (drawRef.current) {
      const data = drawRef.current.getAll();
      if (data.features.length > 0) {
        try {
          const response = await fetch(BACKEND_URL + "/retrieve_obj", {
            method: "POST",
            headers: {
              "Content-Type": "application/json",
            },
            body: JSON.stringify({ region: data }),
          });

          if (response.ok) {
            const blob = await response.blob();
            const url = window.URL.createObjectURL(blob);
            const a = document.createElement("a");
            a.style.display = "none";
            a.href = url;
            // Use the filename from the Content-Disposition header if available
            const contentDisposition = response.headers.get("Content-Disposition");
            const filenameMatch =
              contentDisposition && contentDisposition.match(/filename="?(.+)"?/i);
            a.download = filenameMatch
              ? filenameMatch[1]
              : `object_file.obj`;
            document.body.appendChild(a);
            a.click();
            window.URL.revokeObjectURL(url);
          } else {
            console.error("Failed to fetch obj file");
          }
        } catch (error) {
          console.error("Error fetching obj file:", error);
        }
      } else {
        console.error("No polygon drawn");
      }
    }
  };

  const handleZoomChange = (event: any) => {
    const newZoom = event.viewState.zoom;
    setViewState(event.viewState);

    // Toggle visibility based on zoom level
    if (newZoom < 15) {
      setIsLod2Visible(false);
    } else {
      setIsLod2Visible(true);
    }
  };

// Create ambient light
const ambientLight = new AmbientLight({
  color: [240, 255, 255],
  intensity: 1.0
});

// Create directional light
const directionalLight1 = new DirectionalLight({
  color: [220, 255, 255],
  intensity: 0.6,
  direction: [-1, -3, -1]
});

// Create directional light
const directionalLight2 = new DirectionalLight({
  color:  [255, 220, 255],
  intensity: 1,
  direction: [1, -3, 1]
});

// Create lighting effect
const lightingEffect = new LightingEffect({ambientLight, directionalLight1 ,directionalLight2});


  const layers = [
    new Tile3DLayer({
      id: "tile-3d-layer",
      data: TILESET_URL,
      pickable: true,
      autoHighlight: false,
      onClick: (info, event) => console.log("Clicked:", info, event),
      getPickingInfo: (pickParams) => console.log("PickInfo", pickParams),
      onTilesetLoad,
      visible: true,
      // For ScenegraphLayer (b3dm or i3dm format)
      _lighting: 'pbr',
      effects: [lightingEffect],
      // Additional sublayer props for fine-grained control
      _subLayerProps: {
        scenegraph: {
          getColor: (d) => [254, 254, 254, 255], // Blue color for scenegraph models (alternative method)
      effects: [lightingEffect]
        }
      }
    }),
  ];

  const handleSearch = async (query: string) => {
    const response = await fetch(
      `https://nominatim.openstreetmap.org/search?format=json&q=${encodeURIComponent(query)}&countrycodes=de`
    );
    const data = await response.json();
    return data;
  };
  
  const handleSelectResult = (result: any) => {
    // Fly to the selected location
    const map = mapRef.current.getMap();

    map.flyTo({
      center: [parseFloat(result.lon), parseFloat(result.lat)],
      zoom: 14
    });
  };

  return (
    <div style={{ position: "relative", width: "100%", height: "100vh" }}>
      <Map
        initialViewState={viewState}
        mapStyle={MAP_STYLE}
        onLoad={handleMapLoad} // Ensure map is passed here
        onMove={handleZoomChange}
        ref={mapRef}
        style={{ width: "100%", height: "100%" }}
      >
        {selected && (
          <Popup
            key={selected.properties.name}
            anchor="bottom"
            style={{ zIndex: 10 }}
            longitude={selected.geometry.coordinates[0]}
            latitude={selected.geometry.coordinates[1]}
          >
            {selected.properties.name} ({selected.properties.abbrev})
          </Popup>
        )}
        <DeckGLOverlay layers={layers}   effects={[lightingEffect]} // Apply the custom lighting effect globally
 />
        {/* <DrawControl
          ref={drawRef}
          onCreate={onUpdate}
          onUpdate={onUpdate}
          onDelete={onDelete}
        /> */}
        <NavigationControl position="top-left" />

        <DrawControl
          position="top-right"
          displayControlsDefault={false}
          controls={{
            polygon: false,
            trash: false
          }}
          defaultMode="draw_polygon"
          onCreate={onUpdate}
          onUpdate={onUpdate}
          onDelete={onDelete}
        />
      </Map>
      <FloatingPanel
        onDrawPolygon={handleDrawPolygon}
        onRemovePolygon={handleRemovePolygon}
        onFetchObjFile={handleFetchObjFile}
        polygonArea={polygonArea}
  onSearch={handleSearch}
  onSelectResult={handleSelectResult}
      />
      
      <LegalDocuments />
    </div>
  );
}

interface DrawControlProps {
  onCreate: (e: any) => void;
  onUpdate: (e: any) => void;
  onDelete: (e: any) => void;
}

const container = document.body.appendChild(document.createElement("div"));
createRoot(container).render(<Root />);


&&& FILE: ./frontend\src\basemap.json
&&& CONTENT:
{
  "version": 8,
  "name": "Positron",
  "metadata": {
    "mapbox:autocomposite": false,
    "mapbox:groups": {
      "101da9f13b64a08fa4b6ac1168e89e5f": {
        "collapsed": false,
        "name"
................................

&&& FILE: ./frontend\src\CheckoutForm.tsx
&&& CONTENT:
import React, { useState } from "react";
import { useStripe, useElements, CardElement } from "@stripe/react-stripe-js";

interface CheckoutFormProps {
  price: number;
  onFetchObjFile: () => void;
}

interface CustomerData {
  email: string;
  name: string;
  address: {
    line1: string;
    postal_code: string;
    city: string;
    country: string;
  };
}
const CheckoutForm: React.FC<CheckoutFormProps> = ({ price, onFetchObjFile }) => {
  const stripe = useStripe();
  const elements = useElements();
  const [loading, setLoading] = useState(false);
  const [isExpanded, setIsExpanded] = useState(false);
  const [customerData, setCustomerData] = useState<CustomerData>({
    email: "",
    name: "",
    address: {
      line1: "",
      postal_code: "",
      city: "",
      country: "DE",
    },
  });

  // If price is 0, render only the download button
  if (price === 0) {
    return (
      <button 
        onClick={onFetchObjFile}
        className="btn btn-primary btn-sm mt-2"
      >
        Download File
      </button>
    );
  }

  const handleFocus = () => {
    setIsExpanded(true);
  };
  const handleFocusOut = () => {
    setIsExpanded(false);
  };

  const handleSubmit = async (e: React.FormEvent) => {
    e.preventDefault();
    if (!stripe || !elements) return;

    if (!customerData.email || !customerData.name || !customerData.address.line1 || 
        !customerData.address.postal_code || !customerData.address.city) {
      document.getElementById("payment-message")!.textContent = "Please fill in all required fields.";
      return;
    }

    setLoading(true);

    try {
      const response = await fetch(import.meta.env.VITE_BACKEND_URL + "/create-payment-intent", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ 
          amount: Math.round(price * 100),
          customer: customerData
        }),
      });

      if (!response.ok) throw new Error("Failed to create PaymentIntent.");

      const { clientSecret } = await response.json();

      const result = await stripe.confirmCardPayment(clientSecret, {
        payment_method: {
          billing_details: {
            name: customerData.name,
            email: customerData.email,
            address: {
              line1: customerData.address.line1,
              postal_code: customerData.address.postal_code,
              city: customerData.address.city,
              country: customerData.address.country,
            },
          },
          card: elements.getElement(CardElement)!,
        },
      });

      if (result.error) {
        document.getElementById("payment-message")!.textContent = result.error.message;
      } else if (result.paymentIntent?.status === "succeeded") {
        document.getElementById("payment-message")!.textContent = "Success! Your download will start soon.";
        onFetchObjFile();
      }
    } catch (error) {
      console.error("Payment error:", error);
    } finally {
      setLoading(false);
    }
  };
  return (
    <form onSubmit={handleSubmit} className="d-flex flex-column gap-2">
      
      {/* Secure Payment Badge */}
      <div className="d-flex align-items-center gap-1 text-secondary small">
        <span className="bi bi-lock-fill"></span>
        Secure payment via Stripe
      </div>
  
      {/* Price Details */}
      <div className="text-secondary small">
        <p>
          <strong>Order Total:</strong> ‚Ç¨{price.toFixed(2)}
        </p>
        <p>No additional fees. You‚Äôll only be charged this amount.</p>
      </div>
  
      {isExpanded && (
        <div className="mt-2 animate__animated animate__fadeIn">
          {/* Customer Details */}
          <input
            type="email"
            placeholder="Email *"
            required
            value={customerData.email}
            onChange={(e) =>
              setCustomerData({ ...customerData, email: e.target.value })
            }
            className="form-control form-control-sm mb-2"
          />
          <input
            type="text"
            placeholder="Full Name *"
            required
            value={customerData.name}
            onChange={(e) =>
              setCustomerData({ ...customerData, name: e.target.value })
            }
            className="form-control form-control-sm mb-2"
          />
          <input
            type="text"
            placeholder="Street Address *"
            required
            value={customerData.address.line1}
            onChange={(e) =>
              setCustomerData({
                ...customerData,
                address: { ...customerData.address, line1: e.target.value },
              })
            }
            className="form-control form-control-sm mb-2"
          />
          <div className="d-flex gap-2 mb-2">
            <input
              type="text"
              placeholder="Postal Code *"
              required
              value={customerData.address.postal_code}
              onChange={(e) =>
                setCustomerData({
                  ...customerData,
                  address: {
                    ...customerData.address,
                    postal_code: e.target.value,
                  },
                })
              }
              className="form-control form-control-sm"
            />
            <input
              type="text"
              placeholder="City *"
              required
              value={customerData.address.city}
              onChange={(e) =>
                setCustomerData({
                  ...customerData,
                  address: { ...customerData.address, city: e.target.value },
                })
              }
              className="form-control form-control-sm"
            />
          </div>
        </div>
      )}
  
      {/* Card Element */}
      <CardElement
      
      onFocus={handleFocus}
      onFocusOut={handleFocusOut}
        options={{
          style: {
            base: {
              fontSize: "14px",
            },
          },
        }}
      />
      <div id="payment-message" className="text-danger small"></div>
  
      {/* Link to Stripe Security Info */}
      <div className="small mt-7">
        <a
          href="https://stripe.com/docs/security"
          target="_blank"
          rel="noopener noreferrer"
          className="text-secondary"
        >
          Learn more about how your payment information is secured.
        </a>
      </div>
  
      <button
        type="submit"
        disabled={!stripe || loading}
        className="btn btn-primary btn-sm mt-2"
      >
        {loading ? "Processing..." : `Pay ‚Ç¨${price.toFixed(2)}`}
      </button>
    </form>
  );
  
};
export default CheckoutForm;

&&& FILE: ./frontend\src\draw-control.ts
&&& CONTENT:
import MapboxDraw from '@mapbox/mapbox-gl-draw';
import {useControl} from 'react-map-gl';

import type {MapRef, ControlPosition} from 'react-map-gl';

type DrawControlProps = ConstructorParameters<typeof MapboxDraw>[0] & {
  position?: ControlPosition;

  onCreate?: (evt: {features: object[]}) => void;
  onUpdate?: (evt: {features: object[]; action: string}) => void;
  onDelete?: (evt: {features: object[]}) => void;
};

export default function DrawControl(props: DrawControlProps) {
  useControl<MapboxDraw>(
    () => new MapboxDraw(props),
    ({map}: {map: MapRef}) => {
      map.on('draw.create', props.onCreate);
      map.on('draw.update', props.onUpdate);
      map.on('draw.delete', props.onDelete);
    },
    ({map}: {map: MapRef}) => {
      map.off('draw.create', props.onCreate);
      map.off('draw.update', props.onUpdate);
      map.off('draw.delete', props.onDelete);
    },
    {
      position: props.position
    }
  );

  return null;
}

DrawControl.defaultProps = {
  onCreate: () => {},
  onUpdate: () => {},
  onDelete: () => {}
};

&&& FILE: ./frontend\src\FloatingPanel.tsx
&&& CONTENT:
import React, { useState, useEffect } from "react";
import { loadStripe } from "@stripe/stripe-js";
import { Elements } from "@stripe/react-stripe-js";
import CheckoutForm from "./CheckoutForm";
import "bootstrap/dist/css/bootstrap.min.css";
// Import FontAwesome
import { FontAwesomeIcon } from '@fortawesome/react-fontawesome';
import { faChevronUp, faChevronDown } from '@fortawesome/free-solid-svg-icons';

// Initialize Stripe with your publishable key
const stripePromise = loadStripe(
  "hidden_api"
);

interface FloatingPanelProps {
  onDrawPolygon: () => void;
  onRemovePolygon: () => void;
  onFetchObjFile: () => void;
  polygonArea: number | null; // in square kilometers
  onSearch: (query: string) => Promise<any>;
  onSelectResult: (result: any) => void;
}

const FloatingPanel: React.FC<FloatingPanelProps> = ({
  onDrawPolygon,
  onRemovePolygon,
  onFetchObjFile,
  polygonArea,
  onSearch,
  onSelectResult,
}) => {
  const [price, setPrice] = useState<number>(0);

  const [searchQuery, setSearchQuery] = useState("");
  const [searchResults, setSearchResults] = useState<any[]>([]);
  const [isSearching, setIsSearching] = useState(false);

  // New state for expanded tab
  const [expandedTab, setExpandedTab] = useState<string | null>(null);

  const [isMobile, setIsMobile] = useState<boolean>(
    window.innerWidth <= 768
  );

  useEffect(() => {
    if (polygonArea !== null) {
      if (polygonArea < 0.2) {
        setPrice(0);
      } else {
        setPrice(5 * polygonArea);
      }
    }
  }, [polygonArea]);

  // Handle window resize to update isMobile state
  useEffect(() => {
    const handleResize = () => {
      setIsMobile(window.innerWidth <= 768);
    };

    window.addEventListener("resize", handleResize);
    return () => window.removeEventListener("resize", handleResize);
  }, []);

  // Handle search functionality
  const handleSearch = async (e: React.ChangeEvent<HTMLInputElement>) => {
    const query = e.target.value;
    setSearchQuery(query);

    if (query.length > 2) {
      setIsSearching(true);
      try {
        const results = await onSearch(query);
        setSearchResults(results);
      } catch (error) {
        console.error("Search error:", error);
        setSearchResults([]);
      }
      setIsSearching(false);
    } else {
      setSearchResults([]);
    }
  };

  // Extracted content functions for reuse
  const renderAuswahlContent = () => (
    <>
      {/* Search Input */}
      <div className="w-100 mb-3 position-relative">
        <input
          type="text"
          className="form-control form-control-sm"
          placeholder="Search location..."
          value={searchQuery}
          onChange={handleSearch}
        />

        {/* Search Results */}
        {searchResults.length > 0 && (
          <div
            className="position-absolute bg-white shadow-sm rounded mt-1 w-100 overflow-auto"
            style={{
              maxHeight: "150px",
              zIndex: 1060,
            }}
          >
            {searchResults.map((result, index) => (
              <div
                key={index}
                className="p-2 hover-bg-light cursor-pointer"
                onClick={() => {
                  onSelectResult(result);
                  setSearchResults([]);
                  setSearchQuery("");
                }}
                style={{ cursor: "pointer" }}
              >
                {result.display_name || result.name}
              </div>
            ))}
          </div>
        )}

        {isSearching && (
          <div className="text-center mt-2">
            <small>Suche...</small>
          </div>
        )}
      </div>

      {/* Polygon Area and Price Display */}
      {polygonArea !== null ? (
        <div className="text-center mb-3">
          <strong>Gebietfl√§che:</strong> {polygonArea.toFixed(2)} km¬≤
        </div>
      ) : (
        <p className="text-center mb-3">Zeichnen Sie das Gebiet ein</p>
      )}

      {/* Action Buttons */}
      <div className="btn-group w-100" role="group">
        <button
          type="button"
          className="btn btn-outline-primary"
          onClick={onDrawPolygon}
        >
          Draw Polygon
        </button>
        <button
          type="button"
          className="btn btn-outline-danger"
          onClick={onRemovePolygon}
        >
          Delete Polygon
        </button>
      </div>
    </>
  );

  const renderHerunterladenContent = () => (
    <>
      <Elements stripe={stripePromise}>
        <CheckoutForm price={price} onFetchObjFile={onFetchObjFile} />
      </Elements>
    </>
  );

  // Mobile Layout
  if (isMobile) {
    return (
      <div
        className="position-fixed"
        style={{
          bottom: "40px",
          left: "0",
          right: "0",
          zIndex: 1050,
          pointerEvents: "none",
        }}
      >
        {/* Auswahl Tab */}
        <div
          style={{
            pointerEvents: "auto",
            marginBottom: expandedTab === 'Auswahl' ? '0' : '10px',
          }}
        >
          <div
            className={`bg-white shadow p-3 d-flex justify-content-between align-items-center ${
              expandedTab === 'Auswahl' ? 'rounded-top' : 'rounded'
            }`}
            style={{
              margin: "0 20px",
              cursor: "pointer",
            }}
            onClick={() => {
              setExpandedTab(expandedTab === 'Auswahl' ? null : 'Auswahl');
            }}
          >
            <h5 className="mb-0">Auswahl</h5>
            {/* Expand/Collapse Icon */}
            <FontAwesomeIcon
              icon={expandedTab === 'Auswahl' ? faChevronUp : faChevronDown}
            />
          </div>
          {expandedTab === 'Auswahl' && (
            <div
              className="bg-white shadow p-3 rounded-bottom"
              style={{
                margin: "0 20px 20px",
              }}
            >
              {renderAuswahlContent()}
            </div>
          )}
        </div>

        {/* Herunterladen Tab */}
        <div
          style={{
            pointerEvents: "auto",
            marginBottom: expandedTab === 'Herunterladen' ? '0' : '10px',
          }}
        >
          <div
            className={`bg-white shadow p-3 d-flex justify-content-between align-items-center ${
              expandedTab === 'Herunterladen' ? 'rounded-top' : 'rounded'
            }`}
            style={{
              margin: "0 20px",
              cursor: "pointer",
            }}
            onClick={() => {
              setExpandedTab(expandedTab === 'Herunterladen' ? null : 'Herunterladen');
            }}
          >
            <h5 className="mb-0">Herunterladen</h5>
            {/* Expand/Collapse Icon */}
            <FontAwesomeIcon
              icon={expandedTab === 'Herunterladen' ? faChevronUp : faChevronDown}
            />
          </div>
          {expandedTab === 'Herunterladen' && (
            <div
              className="bg-white shadow p-3 rounded-bottom"
              style={{
                margin: "0 20px 20px",
              }}
            >
              {renderHerunterladenContent()}
            </div>
          )}
        </div>
      </div>
    );
  }

  // Desktop Layout remains unchanged
  return (
    <div
      className="d-flex align-items-end"
      style={{
        position: "absolute",
        bottom: "20px",
        left: "20px",
        right: "20px",
        gap: "20px",
        zIndex: 1050,
        pointerEvents: "none",
      }}
    >
      <div
        className="d-flex gap-3"
        style={{
          marginRight: "auto",
          pointerEvents: "none",
        }}
      >
        {/* Auswahl Panel */}
        <div
          className="bg-white rounded shadow p-3 d-flex flex-column align-items-center justify-content-center"
          style={{
            width: "300px",
            minHeight: "200px",
            pointerEvents: "auto",
          }}
        >
          <h5 className="mb-3 text-center">Auswahl</h5>
          {renderAuswahlContent()}
        </div>
      </div>

      {/* Herunterladen Panel */}
      <div
        className="bg-white rounded shadow p-3 d-flex flex-column "
        style={{
          width: "300px",
          minHeight: "50px",
          marginLeft: "auto",
          transition: "height 0.3s ease-in-out",
          pointerEvents: "auto",
        }}
      >
        <h5 className="mb-3 text-center">Herunterladen</h5>
        {renderHerunterladenContent()}
      </div>
    </div>
  );
};

export default FloatingPanel;


&&& FILE: ./frontend\src\Legals.tsx
&&& CONTENT:
import React, { useState, useEffect } from 'react';
import ReactMarkdown from 'react-markdown';

const LegalDocumentPanel: React.FC<{
  documentType: string;
  isOpen: boolean;
  setOpenDocument: (doc: string | null) => void;
}> = ({ documentType, isOpen, setOpenDocument }) => {
  const [content, setContent] = useState('');

  useEffect(() => {
    if (isOpen && !content) {
      const fetchContent = async () => {
        try {
          const response = await fetch(`/docs/${documentType}.md`);
          const text = await response.text();
          setContent(text);
        } catch (error) {
          console.error(`Error loading ${documentType}:`, error);
          setContent('Failed to load content.');
        }
      };
      fetchContent();
    }
  }, [isOpen, content, documentType]);

  const handleClick = () => {
    setOpenDocument(isOpen ? null : documentType);
  };

  return (
    <>
      <button
        onClick={handleClick}
        className="btn btn-sm btn-light"
        style={{
          display: 'inline-block',
          padding: '0.25rem 0.5rem',
        }}
      >
        {documentType.charAt(0).toUpperCase() + documentType.slice(1)}
      </button>

      {isOpen && (
        <div
          className="bg-white rounded shadow p-3"
          style={{
            position: 'absolute',
            top: '50px',
            right: '10px',
            maxWidth: '600px',
            width: '80vw',
            maxHeight: '50vh',
            overflowY: 'auto',
            zIndex: 1070,
          }}
        >
          <button
            className="btn btn-sm btn-close float-end"
            onClick={() => setOpenDocument(null)}
          />
          <h5 className="mb-3">
            {documentType.charAt(0).toUpperCase() + documentType.slice(1)}
          </h5>
          <ReactMarkdown>{content}</ReactMarkdown>
        </div>
      )}
    </>
  );
};

const LegalDocuments: React.FC = () => {
  const [openDocument, setOpenDocument] = useState<string | null>(null);

  return (
    <div
      style={{
        position: 'absolute',
        top: '10px',
        right: '10px',
        display: 'flex',
        gap: '20px',
        zIndex: 1060,
      }}
    >
      <LegalDocumentPanel
        documentType="impressum"
        isOpen={openDocument === 'impressum'}
        setOpenDocument={setOpenDocument}
      />
      <LegalDocumentPanel
        documentType="datenschutz"
        isOpen={openDocument === 'datenschutz'}
        setOpenDocument={setOpenDocument}
      />
      <LegalDocumentPanel
        documentType="agb"
        isOpen={openDocument === 'agb'}
        setOpenDocument={setOpenDocument}
      />
      <LegalDocumentPanel
        documentType="widerruf"
        isOpen={openDocument === 'widerruf'}
        setOpenDocument={setOpenDocument}
      />
    </div>
  );
};

export default LegalDocuments;


